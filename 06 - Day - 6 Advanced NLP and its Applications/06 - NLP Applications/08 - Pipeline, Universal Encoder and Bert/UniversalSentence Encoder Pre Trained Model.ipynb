{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "instructional-boundary",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow_hub as hub\n",
    "module = hub.load(\"https://tfhub.dev/google/universal-sentence-encoder-large/3\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "solid-enzyme",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tensorflow_text\n",
      "  Downloading tensorflow_text-2.4.3-cp37-cp37m-macosx_10_9_x86_64.whl (2.8 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.8 MB 2.8 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: tensorflow-hub>=0.8.0 in /opt/anaconda3/envs/dl-nlp/lib/python3.7/site-packages (from tensorflow_text) (0.12.0)\n",
      "Collecting tensorflow<2.5,>=2.4.0\n",
      "  Using cached tensorflow-2.4.1-cp37-cp37m-macosx_10_11_x86_64.whl (173.9 MB)\n",
      "Requirement already satisfied: absl-py~=0.10 in /opt/anaconda3/envs/dl-nlp/lib/python3.7/site-packages (from tensorflow<2.5,>=2.4.0->tensorflow_text) (0.12.0)\n",
      "Requirement already satisfied: flatbuffers~=1.12.0 in /opt/anaconda3/envs/dl-nlp/lib/python3.7/site-packages (from tensorflow<2.5,>=2.4.0->tensorflow_text) (1.12)\n",
      "Collecting tensorflow-estimator<2.5.0,>=2.4.0\n",
      "  Using cached tensorflow_estimator-2.4.0-py2.py3-none-any.whl (462 kB)\n",
      "Requirement already satisfied: termcolor~=1.1.0 in /opt/anaconda3/envs/dl-nlp/lib/python3.7/site-packages (from tensorflow<2.5,>=2.4.0->tensorflow_text) (1.1.0)\n",
      "Requirement already satisfied: numpy~=1.19.2 in /opt/anaconda3/envs/dl-nlp/lib/python3.7/site-packages (from tensorflow<2.5,>=2.4.0->tensorflow_text) (1.19.5)\n",
      "Requirement already satisfied: keras-preprocessing~=1.1.2 in /opt/anaconda3/envs/dl-nlp/lib/python3.7/site-packages (from tensorflow<2.5,>=2.4.0->tensorflow_text) (1.1.2)\n",
      "Requirement already satisfied: typing-extensions~=3.7.4 in /opt/anaconda3/envs/dl-nlp/lib/python3.7/site-packages (from tensorflow<2.5,>=2.4.0->tensorflow_text) (3.7.4.3)\n",
      "Requirement already satisfied: protobuf>=3.9.2 in /opt/anaconda3/envs/dl-nlp/lib/python3.7/site-packages (from tensorflow<2.5,>=2.4.0->tensorflow_text) (3.15.6)\n",
      "Requirement already satisfied: wheel~=0.35 in /opt/anaconda3/envs/dl-nlp/lib/python3.7/site-packages (from tensorflow<2.5,>=2.4.0->tensorflow_text) (0.36.2)\n",
      "Collecting gast==0.3.3\n",
      "  Using cached gast-0.3.3-py2.py3-none-any.whl (9.7 kB)\n",
      "Requirement already satisfied: opt-einsum~=3.3.0 in /opt/anaconda3/envs/dl-nlp/lib/python3.7/site-packages (from tensorflow<2.5,>=2.4.0->tensorflow_text) (3.3.0)\n",
      "Requirement already satisfied: astunparse~=1.6.3 in /opt/anaconda3/envs/dl-nlp/lib/python3.7/site-packages (from tensorflow<2.5,>=2.4.0->tensorflow_text) (1.6.3)\n",
      "Requirement already satisfied: h5py~=2.10.0 in /opt/anaconda3/envs/dl-nlp/lib/python3.7/site-packages (from tensorflow<2.5,>=2.4.0->tensorflow_text) (2.10.0)\n",
      "Requirement already satisfied: wrapt~=1.12.1 in /opt/anaconda3/envs/dl-nlp/lib/python3.7/site-packages (from tensorflow<2.5,>=2.4.0->tensorflow_text) (1.12.1)\n",
      "Collecting tensorboard~=2.4\n",
      "  Using cached tensorboard-2.4.1-py3-none-any.whl (10.6 MB)\n",
      "Requirement already satisfied: six~=1.15.0 in /opt/anaconda3/envs/dl-nlp/lib/python3.7/site-packages (from tensorflow<2.5,>=2.4.0->tensorflow_text) (1.15.0)\n",
      "Requirement already satisfied: google-pasta~=0.2 in /opt/anaconda3/envs/dl-nlp/lib/python3.7/site-packages (from tensorflow<2.5,>=2.4.0->tensorflow_text) (0.2.0)\n",
      "Requirement already satisfied: grpcio~=1.32.0 in /opt/anaconda3/envs/dl-nlp/lib/python3.7/site-packages (from tensorflow<2.5,>=2.4.0->tensorflow_text) (1.32.0)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /opt/anaconda3/envs/dl-nlp/lib/python3.7/site-packages (from tensorboard~=2.4->tensorflow<2.5,>=2.4.0->tensorflow_text) (3.3.4)\n",
      "Requirement already satisfied: werkzeug>=0.11.15 in /opt/anaconda3/envs/dl-nlp/lib/python3.7/site-packages (from tensorboard~=2.4->tensorflow<2.5,>=2.4.0->tensorflow_text) (1.0.1)\n",
      "Requirement already satisfied: google-auth<2,>=1.6.3 in /opt/anaconda3/envs/dl-nlp/lib/python3.7/site-packages (from tensorboard~=2.4->tensorflow<2.5,>=2.4.0->tensorflow_text) (1.27.1)\n",
      "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /opt/anaconda3/envs/dl-nlp/lib/python3.7/site-packages (from tensorboard~=2.4->tensorflow<2.5,>=2.4.0->tensorflow_text) (0.4.3)\n",
      "Requirement already satisfied: setuptools>=41.0.0 in /opt/anaconda3/envs/dl-nlp/lib/python3.7/site-packages (from tensorboard~=2.4->tensorflow<2.5,>=2.4.0->tensorflow_text) (52.0.0.post20210125)\n",
      "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /opt/anaconda3/envs/dl-nlp/lib/python3.7/site-packages (from tensorboard~=2.4->tensorflow<2.5,>=2.4.0->tensorflow_text) (1.8.0)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in /opt/anaconda3/envs/dl-nlp/lib/python3.7/site-packages (from tensorboard~=2.4->tensorflow<2.5,>=2.4.0->tensorflow_text) (2.25.1)\n",
      "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /opt/anaconda3/envs/dl-nlp/lib/python3.7/site-packages (from google-auth<2,>=1.6.3->tensorboard~=2.4->tensorflow<2.5,>=2.4.0->tensorflow_text) (4.2.1)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /opt/anaconda3/envs/dl-nlp/lib/python3.7/site-packages (from google-auth<2,>=1.6.3->tensorboard~=2.4->tensorflow<2.5,>=2.4.0->tensorflow_text) (4.7.2)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /opt/anaconda3/envs/dl-nlp/lib/python3.7/site-packages (from google-auth<2,>=1.6.3->tensorboard~=2.4->tensorflow<2.5,>=2.4.0->tensorflow_text) (0.2.8)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in /opt/anaconda3/envs/dl-nlp/lib/python3.7/site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.4->tensorflow<2.5,>=2.4.0->tensorflow_text) (1.3.0)\n",
      "Requirement already satisfied: importlib-metadata in /opt/anaconda3/envs/dl-nlp/lib/python3.7/site-packages (from markdown>=2.6.8->tensorboard~=2.4->tensorflow<2.5,>=2.4.0->tensorflow_text) (3.7.2)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /opt/anaconda3/envs/dl-nlp/lib/python3.7/site-packages (from pyasn1-modules>=0.2.1->google-auth<2,>=1.6.3->tensorboard~=2.4->tensorflow<2.5,>=2.4.0->tensorflow_text) (0.4.8)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /opt/anaconda3/envs/dl-nlp/lib/python3.7/site-packages (from requests<3,>=2.21.0->tensorboard~=2.4->tensorflow<2.5,>=2.4.0->tensorflow_text) (2.10)\n",
      "Requirement already satisfied: chardet<5,>=3.0.2 in /opt/anaconda3/envs/dl-nlp/lib/python3.7/site-packages (from requests<3,>=2.21.0->tensorboard~=2.4->tensorflow<2.5,>=2.4.0->tensorflow_text) (4.0.0)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/anaconda3/envs/dl-nlp/lib/python3.7/site-packages (from requests<3,>=2.21.0->tensorboard~=2.4->tensorflow<2.5,>=2.4.0->tensorflow_text) (1.26.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/anaconda3/envs/dl-nlp/lib/python3.7/site-packages (from requests<3,>=2.21.0->tensorboard~=2.4->tensorflow<2.5,>=2.4.0->tensorflow_text) (2020.12.5)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /opt/anaconda3/envs/dl-nlp/lib/python3.7/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.4->tensorflow<2.5,>=2.4.0->tensorflow_text) (3.1.0)\n",
      "Requirement already satisfied: zipp>=0.5 in /opt/anaconda3/envs/dl-nlp/lib/python3.7/site-packages (from importlib-metadata->markdown>=2.6.8->tensorboard~=2.4->tensorflow<2.5,>=2.4.0->tensorflow_text) (3.4.1)\n",
      "Installing collected packages: tensorflow-estimator, tensorboard, gast, tensorflow, tensorflow-text\n",
      "  Attempting uninstall: tensorflow-estimator\n",
      "    Found existing installation: tensorflow-estimator 1.15.1\n",
      "    Uninstalling tensorflow-estimator-1.15.1:\n",
      "      Successfully uninstalled tensorflow-estimator-1.15.1\n",
      "  Attempting uninstall: tensorboard\n",
      "    Found existing installation: tensorboard 1.15.0\n",
      "    Uninstalling tensorboard-1.15.0:\n",
      "      Successfully uninstalled tensorboard-1.15.0\n",
      "  Attempting uninstall: gast\n",
      "    Found existing installation: gast 0.2.2\n",
      "    Uninstalling gast-0.2.2:\n",
      "      Successfully uninstalled gast-0.2.2\n",
      "  Attempting uninstall: tensorflow\n",
      "    Found existing installation: tensorflow 1.15.0\n",
      "    Uninstalling tensorflow-1.15.0:\n",
      "      Successfully uninstalled tensorflow-1.15.0\n",
      "Successfully installed gast-0.3.3 tensorboard-2.4.1 tensorflow-2.4.1 tensorflow-estimator-2.4.0 tensorflow-text-2.4.3\n"
     ]
    }
   ],
   "source": [
    "!pip install tensorflow_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "certain-harvard",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow_hub as hub\n",
    "import numpy as np\n",
    "import tensorflow_text\n",
    "\n",
    "# Some texts of different lengths.\n",
    "english_sentences = [\"dog\", \"Puppies are nice.\", \"I enjoy taking long walks along the beach with my dog.\"]\n",
    "italian_sentences = [\"cane\", \"I cuccioli sono carini.\", \"Mi piace fare lunghe passeggiate lungo la spiaggia con il mio cane.\"]\n",
    "japanese_sentences = [\"犬\", \"子犬はいいです\", \"私は犬と一緒にビーチを散歩するのが好きです\"]\n",
    "\n",
    "embed = hub.load(\"https://tfhub.dev/google/universal-sentence-encoder-multilingual-large/3\")\n",
    "\n",
    "# Compute embeddings.\n",
    "en_result = embed(english_sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "confident-thong",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(3, 512), dtype=float32, numpy=\n",
       "array([[-0.00525213, -0.038312  , -0.00922013, ...,  0.0217905 ,\n",
       "         0.06280179, -0.01622537],\n",
       "       [-0.02267583, -0.06907186,  0.01550871, ...,  0.08762303,\n",
       "        -0.00076926, -0.05410822],\n",
       "       [ 0.01908831,  0.0095522 , -0.0474129 , ...,  0.03206478,\n",
       "         0.03661669,  0.00331061]], dtype=float32)>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "en_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "graduate-worse",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'AutoTrackable' object is not callable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-70f1b9920da6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0muse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msent_1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: 'AutoTrackable' object is not callable"
     ]
    }
   ],
   "source": [
    "sent_1 = [\"the location is great\"]\n",
    "sent_2 = [\"amazing location\"]\n",
    "\n",
    "\n",
    "use(sent_1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "configured-convertible",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sharp-atlantic",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "heated-killer",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"Hotel_Reviews.csv\", parse_dates=['Review_Date'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "structured-movement",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.head(5000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "radical-protein",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"review\"] = df[\"Negative_Review\"] + df[\"Positive_Review\"]\n",
    "df[\"review_type\"] = df[\"Reviewer_Score\"].apply(\n",
    "  lambda x: \"bad\" if x < 7 else \"good\"\n",
    ")\n",
    "df = df[[\"review\", \"review_type\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "embedded-tiffany",
   "metadata": {},
   "outputs": [],
   "source": [
    "good_reviews = df[df[\"review_type\"]==\"good\"]\n",
    "bad_reviews = df[df[\"review_type\"]==\"bad\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "seasonal-storage",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2070, 2)\n"
     ]
    }
   ],
   "source": [
    "good_df = good_reviews.sample(n=len(bad_reviews), random_state=23)\n",
    "bad_df = bad_reviews\n",
    "review_df = good_df.append(bad_df).reset_index(drop=True)\n",
    "print(review_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "affiliated-vegetable",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "type_one_hot = OneHotEncoder(sparse=False).fit_transform(\n",
    "  review_df.review_type.to_numpy().reshape(-1, 1)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "plastic-strap",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_reviews, test_reviews, y_train, y_test =\\\n",
    "  train_test_split(\n",
    "    review_df.review,\n",
    "    type_one_hot,\n",
    "    test_size=.1,\n",
    "    random_state=23\n",
    "  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "inappropriate-struggle",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "moral-wrestling",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1863/1863 [01:35<00:00, 19.45it/s]\n",
      "100%|██████████| 207/207 [00:10<00:00, 18.94it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1863, 512) (1863, 2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "X_train = []\n",
    "for r in tqdm(train_reviews):\n",
    "  emb = embed(r)\n",
    "  review_emb = tf.reshape(emb, [-1]).numpy()\n",
    "  X_train.append(review_emb)\n",
    "X_train = np.array(X_train)\n",
    "X_test = []\n",
    "for r in tqdm(test_reviews):\n",
    "  emb = embed(r)\n",
    "  review_emb = tf.reshape(emb, [-1]).numpy()\n",
    "  X_test.append(review_emb)\n",
    "X_test = np.array(X_test)\n",
    "print(X_train.shape, y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "documentary-invasion",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.Sequential()\n",
    "model.add(keras.layers.Dense(\n",
    "    units=256,\n",
    "    input_shape=(X_train.shape[1], ),\n",
    "    activation='relu'\n",
    "  )\n",
    ")\n",
    "model.add(\n",
    "  keras.layers.Dropout(rate=0.5)\n",
    ")\n",
    "model.add(\n",
    "  keras.layers.Dense(\n",
    "    units=128,\n",
    "    activation='relu'\n",
    "  )\n",
    ")\n",
    "model.add(\n",
    "  keras.layers.Dropout(rate=0.5)\n",
    ")\n",
    "model.add(keras.layers.Dense(2, activation='softmax'))\n",
    "model.compile(\n",
    "    loss='categorical_crossentropy',\n",
    "    optimizer=keras.optimizers.Adam(0.001),\n",
    "    metrics=['accuracy']\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "democratic-connection",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "105/105 [==============================] - 1s 3ms/step - loss: 0.6526 - accuracy: 0.6147 - val_loss: 0.4727 - val_accuracy: 0.7701\n",
      "Epoch 2/100\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.4701 - accuracy: 0.7881 - val_loss: 0.4292 - val_accuracy: 0.8021\n",
      "Epoch 3/100\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.4403 - accuracy: 0.7899 - val_loss: 0.4051 - val_accuracy: 0.8396\n",
      "Epoch 4/100\n",
      "105/105 [==============================] - 0s 1ms/step - loss: 0.4052 - accuracy: 0.8192 - val_loss: 0.3939 - val_accuracy: 0.8556\n",
      "Epoch 5/100\n",
      "105/105 [==============================] - 0s 1ms/step - loss: 0.3618 - accuracy: 0.8422 - val_loss: 0.3975 - val_accuracy: 0.8449\n",
      "Epoch 6/100\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.3489 - accuracy: 0.8511 - val_loss: 0.4125 - val_accuracy: 0.8289\n",
      "Epoch 7/100\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.3236 - accuracy: 0.8692 - val_loss: 0.4361 - val_accuracy: 0.8289\n",
      "Epoch 8/100\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.2729 - accuracy: 0.8947 - val_loss: 0.4835 - val_accuracy: 0.8289\n",
      "Epoch 9/100\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.2187 - accuracy: 0.9243 - val_loss: 0.5054 - val_accuracy: 0.8075\n",
      "Epoch 10/100\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.2059 - accuracy: 0.9199 - val_loss: 0.5493 - val_accuracy: 0.8128\n",
      "Epoch 11/100\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.1646 - accuracy: 0.9430 - val_loss: 0.5776 - val_accuracy: 0.8075\n",
      "Epoch 12/100\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.1517 - accuracy: 0.9444 - val_loss: 0.5938 - val_accuracy: 0.8342\n",
      "Epoch 13/100\n",
      "105/105 [==============================] - 0s 1ms/step - loss: 0.1309 - accuracy: 0.9569 - val_loss: 0.6306 - val_accuracy: 0.7754\n",
      "Epoch 14/100\n",
      "105/105 [==============================] - 0s 1ms/step - loss: 0.1159 - accuracy: 0.9698 - val_loss: 0.6723 - val_accuracy: 0.8075\n",
      "Epoch 15/100\n",
      "105/105 [==============================] - 0s 1ms/step - loss: 0.1222 - accuracy: 0.9540 - val_loss: 0.7500 - val_accuracy: 0.7754\n",
      "Epoch 16/100\n",
      "105/105 [==============================] - 0s 1ms/step - loss: 0.0853 - accuracy: 0.9737 - val_loss: 0.6725 - val_accuracy: 0.7968\n",
      "Epoch 17/100\n",
      "105/105 [==============================] - 0s 1ms/step - loss: 0.0799 - accuracy: 0.9759 - val_loss: 0.7663 - val_accuracy: 0.8075\n",
      "Epoch 18/100\n",
      "105/105 [==============================] - 0s 1ms/step - loss: 0.0991 - accuracy: 0.9624 - val_loss: 0.7447 - val_accuracy: 0.8128\n",
      "Epoch 19/100\n",
      "105/105 [==============================] - 0s 1ms/step - loss: 0.0590 - accuracy: 0.9808 - val_loss: 0.8444 - val_accuracy: 0.8182\n",
      "Epoch 20/100\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.0547 - accuracy: 0.9825 - val_loss: 0.8594 - val_accuracy: 0.8021\n",
      "Epoch 21/100\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.0633 - accuracy: 0.9783 - val_loss: 0.8350 - val_accuracy: 0.7914\n",
      "Epoch 22/100\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.0542 - accuracy: 0.9837 - val_loss: 0.9239 - val_accuracy: 0.7807\n",
      "Epoch 23/100\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.0494 - accuracy: 0.9848 - val_loss: 0.9008 - val_accuracy: 0.7807\n",
      "Epoch 24/100\n",
      "105/105 [==============================] - 0s 1ms/step - loss: 0.0451 - accuracy: 0.9835 - val_loss: 0.9341 - val_accuracy: 0.7968\n",
      "Epoch 25/100\n",
      "105/105 [==============================] - 0s 1ms/step - loss: 0.0450 - accuracy: 0.9846 - val_loss: 0.9373 - val_accuracy: 0.8021\n",
      "Epoch 26/100\n",
      "105/105 [==============================] - 0s 1ms/step - loss: 0.0445 - accuracy: 0.9823 - val_loss: 0.9794 - val_accuracy: 0.7914\n",
      "Epoch 27/100\n",
      "105/105 [==============================] - 0s 1ms/step - loss: 0.0408 - accuracy: 0.9861 - val_loss: 1.0368 - val_accuracy: 0.7807\n",
      "Epoch 28/100\n",
      "105/105 [==============================] - 0s 1ms/step - loss: 0.0381 - accuracy: 0.9876 - val_loss: 0.9673 - val_accuracy: 0.7754\n",
      "Epoch 29/100\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.0557 - accuracy: 0.9752 - val_loss: 1.0163 - val_accuracy: 0.8021\n",
      "Epoch 30/100\n",
      "105/105 [==============================] - 0s 1ms/step - loss: 0.0508 - accuracy: 0.9856 - val_loss: 1.0566 - val_accuracy: 0.7647\n",
      "Epoch 31/100\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.0482 - accuracy: 0.9822 - val_loss: 1.0884 - val_accuracy: 0.7754\n",
      "Epoch 32/100\n",
      "105/105 [==============================] - 0s 1ms/step - loss: 0.0403 - accuracy: 0.9897 - val_loss: 0.9887 - val_accuracy: 0.7807\n",
      "Epoch 33/100\n",
      "105/105 [==============================] - 0s 1ms/step - loss: 0.0581 - accuracy: 0.9816 - val_loss: 0.9166 - val_accuracy: 0.7914\n",
      "Epoch 34/100\n",
      "105/105 [==============================] - 0s 1ms/step - loss: 0.0356 - accuracy: 0.9855 - val_loss: 1.0246 - val_accuracy: 0.7914\n",
      "Epoch 35/100\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.0355 - accuracy: 0.9893 - val_loss: 1.0118 - val_accuracy: 0.8021\n",
      "Epoch 36/100\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.0367 - accuracy: 0.9873 - val_loss: 1.1034 - val_accuracy: 0.8075\n",
      "Epoch 37/100\n",
      "105/105 [==============================] - 0s 1ms/step - loss: 0.0368 - accuracy: 0.9880 - val_loss: 1.0803 - val_accuracy: 0.8128\n",
      "Epoch 38/100\n",
      "105/105 [==============================] - 0s 1ms/step - loss: 0.0418 - accuracy: 0.9895 - val_loss: 1.1183 - val_accuracy: 0.8128\n",
      "Epoch 39/100\n",
      "105/105 [==============================] - 0s 1ms/step - loss: 0.0211 - accuracy: 0.9941 - val_loss: 1.2005 - val_accuracy: 0.8021\n",
      "Epoch 40/100\n",
      "105/105 [==============================] - 0s 1ms/step - loss: 0.0257 - accuracy: 0.9903 - val_loss: 1.1787 - val_accuracy: 0.8021\n",
      "Epoch 41/100\n",
      "105/105 [==============================] - 0s 1ms/step - loss: 0.0264 - accuracy: 0.9896 - val_loss: 1.1300 - val_accuracy: 0.8021\n",
      "Epoch 42/100\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.0307 - accuracy: 0.9909 - val_loss: 1.1753 - val_accuracy: 0.8182\n",
      "Epoch 43/100\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.0382 - accuracy: 0.9889 - val_loss: 1.2198 - val_accuracy: 0.7968\n",
      "Epoch 44/100\n",
      "105/105 [==============================] - 0s 1ms/step - loss: 0.0338 - accuracy: 0.9902 - val_loss: 1.1241 - val_accuracy: 0.8075\n",
      "Epoch 45/100\n",
      "105/105 [==============================] - 0s 1ms/step - loss: 0.0242 - accuracy: 0.9934 - val_loss: 1.2970 - val_accuracy: 0.7807\n",
      "Epoch 46/100\n",
      "105/105 [==============================] - 0s 1ms/step - loss: 0.0262 - accuracy: 0.9899 - val_loss: 1.3582 - val_accuracy: 0.7861\n",
      "Epoch 47/100\n",
      "105/105 [==============================] - 0s 1ms/step - loss: 0.0373 - accuracy: 0.9874 - val_loss: 1.2081 - val_accuracy: 0.7861\n",
      "Epoch 48/100\n",
      "105/105 [==============================] - 0s 1ms/step - loss: 0.0401 - accuracy: 0.9824 - val_loss: 1.2376 - val_accuracy: 0.8021\n",
      "Epoch 49/100\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.0164 - accuracy: 0.9924 - val_loss: 1.3003 - val_accuracy: 0.7914\n",
      "Epoch 50/100\n",
      "105/105 [==============================] - 0s 1ms/step - loss: 0.0363 - accuracy: 0.9904 - val_loss: 1.3739 - val_accuracy: 0.8075\n",
      "Epoch 51/100\n",
      "105/105 [==============================] - 0s 1ms/step - loss: 0.0293 - accuracy: 0.9893 - val_loss: 1.3587 - val_accuracy: 0.7807\n",
      "Epoch 52/100\n",
      "105/105 [==============================] - 0s 1ms/step - loss: 0.0341 - accuracy: 0.9868 - val_loss: 1.2847 - val_accuracy: 0.7807\n",
      "Epoch 53/100\n",
      "105/105 [==============================] - 0s 1ms/step - loss: 0.0186 - accuracy: 0.9930 - val_loss: 1.2546 - val_accuracy: 0.7807\n",
      "Epoch 54/100\n",
      "105/105 [==============================] - 0s 1ms/step - loss: 0.0365 - accuracy: 0.9884 - val_loss: 1.2632 - val_accuracy: 0.8021\n",
      "Epoch 55/100\n",
      "105/105 [==============================] - 0s 1ms/step - loss: 0.0292 - accuracy: 0.9879 - val_loss: 1.2442 - val_accuracy: 0.8021\n",
      "Epoch 56/100\n",
      "105/105 [==============================] - 0s 1ms/step - loss: 0.0213 - accuracy: 0.9932 - val_loss: 1.2184 - val_accuracy: 0.8235\n",
      "Epoch 57/100\n",
      "105/105 [==============================] - 0s 1ms/step - loss: 0.0173 - accuracy: 0.9953 - val_loss: 1.3061 - val_accuracy: 0.8021\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 58/100\n",
      "105/105 [==============================] - 0s 1ms/step - loss: 0.0198 - accuracy: 0.9920 - val_loss: 1.3107 - val_accuracy: 0.8021\n",
      "Epoch 59/100\n",
      "105/105 [==============================] - 0s 1ms/step - loss: 0.0267 - accuracy: 0.9913 - val_loss: 1.3399 - val_accuracy: 0.7807\n",
      "Epoch 60/100\n",
      "105/105 [==============================] - 0s 1ms/step - loss: 0.0194 - accuracy: 0.9948 - val_loss: 1.3987 - val_accuracy: 0.8075\n",
      "Epoch 61/100\n",
      "105/105 [==============================] - 0s 1ms/step - loss: 0.0286 - accuracy: 0.9856 - val_loss: 1.3336 - val_accuracy: 0.7914\n",
      "Epoch 62/100\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.0401 - accuracy: 0.9925 - val_loss: 1.2589 - val_accuracy: 0.7968\n",
      "Epoch 63/100\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.0289 - accuracy: 0.9929 - val_loss: 1.3054 - val_accuracy: 0.7807\n",
      "Epoch 64/100\n",
      "105/105 [==============================] - 0s 1ms/step - loss: 0.0338 - accuracy: 0.9857 - val_loss: 1.2945 - val_accuracy: 0.8021\n",
      "Epoch 65/100\n",
      "105/105 [==============================] - 0s 1ms/step - loss: 0.0143 - accuracy: 0.9953 - val_loss: 1.4901 - val_accuracy: 0.7914\n",
      "Epoch 66/100\n",
      "105/105 [==============================] - 0s 1ms/step - loss: 0.0166 - accuracy: 0.9959 - val_loss: 1.5082 - val_accuracy: 0.7647\n",
      "Epoch 67/100\n",
      "105/105 [==============================] - 0s 1ms/step - loss: 0.0230 - accuracy: 0.9918 - val_loss: 1.6364 - val_accuracy: 0.7807\n",
      "Epoch 68/100\n",
      "105/105 [==============================] - 0s 1ms/step - loss: 0.0344 - accuracy: 0.9886 - val_loss: 1.5127 - val_accuracy: 0.8021\n",
      "Epoch 69/100\n",
      "105/105 [==============================] - 0s 1ms/step - loss: 0.0192 - accuracy: 0.9932 - val_loss: 1.5404 - val_accuracy: 0.7968\n",
      "Epoch 70/100\n",
      "105/105 [==============================] - 0s 1ms/step - loss: 0.0113 - accuracy: 0.9968 - val_loss: 1.6118 - val_accuracy: 0.8021\n",
      "Epoch 71/100\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.0250 - accuracy: 0.9900 - val_loss: 1.5843 - val_accuracy: 0.7807\n",
      "Epoch 72/100\n",
      "105/105 [==============================] - 0s 1ms/step - loss: 0.0185 - accuracy: 0.9937 - val_loss: 1.4016 - val_accuracy: 0.8235\n",
      "Epoch 73/100\n",
      "105/105 [==============================] - 0s 1ms/step - loss: 0.0425 - accuracy: 0.9843 - val_loss: 1.3945 - val_accuracy: 0.8021\n",
      "Epoch 74/100\n",
      "105/105 [==============================] - 0s 1ms/step - loss: 0.0326 - accuracy: 0.9905 - val_loss: 1.4286 - val_accuracy: 0.8128\n",
      "Epoch 75/100\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.0185 - accuracy: 0.9937 - val_loss: 1.4524 - val_accuracy: 0.7861\n",
      "Epoch 76/100\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.0118 - accuracy: 0.9975 - val_loss: 1.4149 - val_accuracy: 0.7861\n",
      "Epoch 77/100\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.0211 - accuracy: 0.9917 - val_loss: 1.6390 - val_accuracy: 0.7914\n",
      "Epoch 78/100\n",
      "105/105 [==============================] - 0s 1ms/step - loss: 0.0306 - accuracy: 0.9886 - val_loss: 1.5181 - val_accuracy: 0.7861\n",
      "Epoch 79/100\n",
      "105/105 [==============================] - 0s 1ms/step - loss: 0.0201 - accuracy: 0.9911 - val_loss: 1.7296 - val_accuracy: 0.7807\n",
      "Epoch 80/100\n",
      "105/105 [==============================] - 0s 1ms/step - loss: 0.0368 - accuracy: 0.9881 - val_loss: 1.5455 - val_accuracy: 0.7861\n",
      "Epoch 81/100\n",
      "105/105 [==============================] - 0s 1ms/step - loss: 0.0217 - accuracy: 0.9903 - val_loss: 1.5180 - val_accuracy: 0.7914\n",
      "Epoch 82/100\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.0363 - accuracy: 0.9901 - val_loss: 1.5000 - val_accuracy: 0.7754\n",
      "Epoch 83/100\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.0108 - accuracy: 0.9979 - val_loss: 1.5533 - val_accuracy: 0.7914\n",
      "Epoch 84/100\n",
      "105/105 [==============================] - 0s 1ms/step - loss: 0.0100 - accuracy: 0.9952 - val_loss: 1.7295 - val_accuracy: 0.7914\n",
      "Epoch 85/100\n",
      "105/105 [==============================] - 0s 1ms/step - loss: 0.0189 - accuracy: 0.9926 - val_loss: 1.7514 - val_accuracy: 0.7968\n",
      "Epoch 86/100\n",
      "105/105 [==============================] - 0s 1ms/step - loss: 0.0193 - accuracy: 0.9874 - val_loss: 1.7269 - val_accuracy: 0.8021\n",
      "Epoch 87/100\n",
      "105/105 [==============================] - 0s 1ms/step - loss: 0.0189 - accuracy: 0.9953 - val_loss: 1.7312 - val_accuracy: 0.7914\n",
      "Epoch 88/100\n",
      "105/105 [==============================] - 0s 1ms/step - loss: 0.0283 - accuracy: 0.9938 - val_loss: 1.7399 - val_accuracy: 0.7968\n",
      "Epoch 89/100\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.0160 - accuracy: 0.9949 - val_loss: 1.6481 - val_accuracy: 0.7861\n",
      "Epoch 90/100\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.0156 - accuracy: 0.9945 - val_loss: 1.7696 - val_accuracy: 0.7861\n",
      "Epoch 91/100\n",
      "105/105 [==============================] - 0s 1ms/step - loss: 0.0216 - accuracy: 0.9947 - val_loss: 1.5560 - val_accuracy: 0.7861\n",
      "Epoch 92/100\n",
      "105/105 [==============================] - 0s 1ms/step - loss: 0.0207 - accuracy: 0.9906 - val_loss: 1.7100 - val_accuracy: 0.7861\n",
      "Epoch 93/100\n",
      "105/105 [==============================] - 0s 1ms/step - loss: 0.0320 - accuracy: 0.9865 - val_loss: 1.6305 - val_accuracy: 0.7914\n",
      "Epoch 94/100\n",
      "105/105 [==============================] - 0s 1ms/step - loss: 0.0297 - accuracy: 0.9879 - val_loss: 1.6793 - val_accuracy: 0.8021\n",
      "Epoch 95/100\n",
      "105/105 [==============================] - 0s 1ms/step - loss: 0.0343 - accuracy: 0.9865 - val_loss: 1.6196 - val_accuracy: 0.7914\n",
      "Epoch 96/100\n",
      "105/105 [==============================] - 0s 1ms/step - loss: 0.0178 - accuracy: 0.9930 - val_loss: 1.5812 - val_accuracy: 0.7861\n",
      "Epoch 97/100\n",
      "105/105 [==============================] - 0s 1ms/step - loss: 0.0216 - accuracy: 0.9910 - val_loss: 1.7282 - val_accuracy: 0.7968\n",
      "Epoch 98/100\n",
      "105/105 [==============================] - 0s 1ms/step - loss: 0.0180 - accuracy: 0.9929 - val_loss: 1.6624 - val_accuracy: 0.7701\n",
      "Epoch 99/100\n",
      "105/105 [==============================] - 0s 1ms/step - loss: 0.0176 - accuracy: 0.9921 - val_loss: 1.6803 - val_accuracy: 0.7487\n",
      "Epoch 100/100\n",
      "105/105 [==============================] - 0s 1ms/step - loss: 0.0208 - accuracy: 0.9888 - val_loss: 1.6933 - val_accuracy: 0.7647\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(\n",
    "    X_train, y_train,\n",
    "    epochs=100,\n",
    "    batch_size=16,\n",
    "    validation_split=0.1,\n",
    "    verbose=1,\n",
    "    shuffle=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "prospective-breath",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7/7 [==============================] - 0s 946us/step - loss: 1.5776 - accuracy: 0.8068\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1.5776022672653198, 0.8067632913589478]"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(X_test, y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "controlled-lincoln",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "innocent-filename",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "looking-presentation",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
